{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from darts.models import TiDEModel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_ta as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data for multiple stocks\n",
    "file_paths = [\"wavelet_reconstructed/Chunghwa_wavelet_reconstructed_only.csv\",\n",
    "              \"wavelet_reconstructed/FET_wavelet_reconstructed_only.csv\",\n",
    "              \"wavelet_reconstructed/Syscom_wavelet_reconstructed_only.csv\"\n",
    "]\n",
    "\n",
    "stock_names = [\"Chunghua\", \"FET\", \"Syscom\"]\n",
    "\n",
    "stock_data = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    data = pd.read_csv(file_path, parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "    data.columns = [\"Adj Close\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "\n",
    "    # Feature engineering\n",
    "    data['MA_5'] = data['Close'].rolling(window=5).mean()\n",
    "    data['MA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['RSI'] = ta.rsi(data['Close'], length=14)\n",
    "    data['Volume_MA_5'] = data['Volume'].rolling(window=5).mean()\n",
    "    data['Price_Range'] = data['High'] - data['Low']\n",
    "    data['Daily_Return'] = ((data['Close'] - data['Open']) / data['Open']) * 100\n",
    "    data['Volume_Change'] = data['Volume'].pct_change() * 100\n",
    "\n",
    "    # Drop NaN values and retain numerical columns\n",
    "    data = data.dropna().select_dtypes(include=[np.number]).astype(np.float32)\n",
    "    stock_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align data by date and ensure the same length\n",
    "aligned_data = pd.concat(stock_data, axis=1, keys=[f\"{stock_names[i]}\" for i in range(len(stock_data))])\n",
    "aligned_data = aligned_data.dropna()\n",
    "\n",
    "# Flatten multi-index columns for simplicity\n",
    "aligned_data.columns = ['_'.join(col) for col in aligned_data.columns]\n",
    "\n",
    "# Define features and target (for all stocks)\n",
    "features = [col for col in aligned_data.columns if not col.endswith('_Close')]\n",
    "targets = [col for col in aligned_data.columns if col.endswith('_Close')]\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(aligned_data), columns=aligned_data.columns, index=aligned_data.index)\n",
    "\n",
    "# Convert data to TimeSeries (multi-variate)\n",
    "multi_series = TimeSeries.from_dataframe(scaled_data, freq='B', fill_missing_dates=True, fillna_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation, and test sets\n",
    "train_size = int(len(multi_series) * 0.9)\n",
    "\n",
    "train_series = multi_series[:train_size]\n",
    "test_series = multi_series[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TiDE model setup and training\n",
    "model = TiDEModel(input_chunk_length=30, output_chunk_length=5)\n",
    "model.fit(train_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define separate scalers for each target\n",
    "target_scalers = {target: MinMaxScaler() for target in targets}\n",
    "\n",
    "# Scale individual targets\n",
    "for target in targets:\n",
    "    scaled_data[target] = target_scalers[target].fit_transform(aligned_data[[target]])\n",
    "\n",
    "# Convert data to TimeSeries (multi-variate)\n",
    "multi_series = TimeSeries.from_dataframe(scaled_data, freq='B', fill_missing_dates=False, fillna_value=0)\n",
    "\n",
    "# Test predictions\n",
    "y_test_pred_scaled = model.predict(n=len(test_series))\n",
    "\n",
    "# Calculate test MSE for each stock\n",
    "test_mse = {}\n",
    "for i, target in enumerate(targets):\n",
    "    # Inverse transform the specific target\n",
    "    actual_values = target_scalers[target].inverse_transform(test_series.univariate_component(i).values())\n",
    "    predicted_values = target_scalers[target].inverse_transform(y_test_pred_scaled.univariate_component(i).values())\n",
    "    mse = mean_squared_error(actual_values.flatten(), predicted_values.flatten())\n",
    "    test_mse[target] = mse\n",
    "\n",
    "print(\"Test MSE for each stock:\")\n",
    "for stock, mse in test_mse.items():\n",
    "    print(f\"{stock}: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test predictions and actual values for each stock\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    # Inverse transform the actual and predicted values for the current stock\n",
    "    actual_values = target_scalers[target].inverse_transform(test_series.univariate_component(i).values())\n",
    "    predicted_values = target_scalers[target].inverse_transform(y_test_pred_scaled.univariate_component(i).values())\n",
    "\n",
    "    # Create a subplot for each stock\n",
    "    plt.subplot(len(targets), 1, i + 1)\n",
    "    plt.plot(test_series.time_index, actual_values, label=\"Actual\", color=\"blue\")\n",
    "    plt.plot(test_series.time_index, predicted_values, label=\"Predicted\", color=\"orange\")\n",
    "    plt.title(f\"{target} - Actual vs Predicted\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Close Price\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the next 5 days\n",
    "future_predictions_scaled = model.predict(n=5)\n",
    "future_predictions = {}\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    # Use the correct scaler for the specific target\n",
    "    future_predictions[target] = target_scalers[target].inverse_transform(\n",
    "        future_predictions_scaled.univariate_component(i).values().reshape(-1, 1)\n",
    "    ).flatten()\n",
    "\n",
    "# Save predictions to CSV\n",
    "future_dates = pd.date_range(start=aligned_data.index[-1] + pd.Timedelta(days=1), periods=5, freq='B')\n",
    "future_df = pd.DataFrame(future_predictions, index=future_dates)\n",
    "\n",
    "# Ensure DataFrame columns are meaningful stock names\n",
    "future_df.columns = [f\"Predicted_{col}\" for col in targets]\n",
    "\n",
    "future_df.to_csv(\"future_predictions_multi_stock.csv\", index_label=\"Date\")\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predicted Close Prices for the Next 5 Days:\")\n",
    "print(future_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
